{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building first level models using _nipype_ and _SPM12_\n",
    "\n",
    "## Base functionality for _megameta_ project\n",
    "\n",
    "-------\n",
    "#### History\n",
    "\n",
    "* 3/29/19 mbod - split preprocessing (unzip, resample, smooth) from modeling steps\n",
    "* 3/28/19 mbod - update pipeline to include resampling to template & SPM path reference\n",
    "* 3/23/19 mbod - include contrast definition in the config JSON file\n",
    "* 3/9/19 mbod - updates from testing template with `darpa1`\n",
    "* 2/27/19 mbod  - modify example notebook to make base functionality notebook\n",
    "\n",
    "-----\n",
    "\n",
    "### Description\n",
    "\n",
    "* Set up a nipype workflow to use SPM12 to make first level models for _megameta_ task data (preprocessed using `batch8` SPM8 scripts) in BIDS derivative format   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "### Template variables\n",
    "\n",
    "* Specify the following values:\n",
    "    1. project name - should be name of folder under `/data00/project/megameta`, e.g. `project1`\n",
    "    2. filename for JSON model specification (should be inside `model_specification` folder), e.g. `p1_image_pmod_likeme.json`\n",
    "    3. TR value in seconds\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "### Setup\n",
    "\n",
    "* import required modules and define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200616-12:15:31,19 nipype.utils INFO:\n",
      "\t Running nipype version 1.4.2 (latest: 1.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: \n",
      "\n",
      " | Starting with Nilearn 0.7.0, all Nistats functionality has been incorporated into Nilearn's stats & reporting modules.\n",
      " | Nistats package will no longer be updated or maintained.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "import os  # system functions\n",
    "\n",
    "# NIYPE FUNCTIONS\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.modelgen as model   # model specification\n",
    "from nipype.interfaces.base import Bunch\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from nilearn import plotting, image\n",
    "from nistats import thresholding\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resolution='medium'\n",
    "#PROJECT_NAME='alcohol'\n",
    "#TASK_NAME='task'\n",
    "#smoothing=[8]\n",
    "#PATH_TO_SPM_FOLDER = '/data00/tools/spm12mega'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matlab path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the way matlab should be called\n",
    "mlab.MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "# If SPM is not in your MATLAB path you should add it here\n",
    "mlab.MatlabCommand.set_default_paths(PATH_TO_SPM_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "* These need to be reformatted to be consistent\n",
    "* as data is not smoothed commented out the `fwhm_size` param - but data probably has a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join('/data00/projects/megameta', PROJECT_NAME)\n",
    "fmriprep_dir = os.path.join(PROJECT_DIR, 'derivatives','fmriprep')\n",
    "batch8_dir=os.path.join(PROJECT_DIR, 'derivatives','batch8')\n",
    "\n",
    "task_func_template = \"{PID}_task-{TASK}_*bold*.nii.gz\"\n",
    "\n",
    "if os.path.exists(fmriprep_dir):\n",
    "    SUBJ_DIR=fmriprep_dir\n",
    "    all_subjects=[s for s in os.listdir(fmriprep_dir)]\n",
    "if os.path.exists(batch8_dir):\n",
    "    SUBJ_DIR=batch8_dir\n",
    "    all_subjects=[s for s in os.listdir(batch8_dir)]\n",
    "\n",
    "subject_list = [subj for subj in all_subjects\n",
    "                   if glob.glob(os.path.join(SUBJ_DIR,subj,'func',\n",
    "                                        task_func_template.format(PID=subj, TASK=TASK_NAME)))\n",
    "                ]\n",
    "\n",
    "output_dir = os.path.join(PROJECT_DIR,'derivatives', 'nipype','resampled_and_smoothed')        # name of output folder\n",
    "working_dir = os.path.join(PROJECT_DIR, 'working', \n",
    "                           'nipype', 'workingdir_preproc_{}'.format(TASK_NAME.upper()))   # name of working directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check to see if output and work directories exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir) \n",
    "\n",
    "if not os.path.exists(working_dir):\n",
    "    os.makedirs(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    subject_list = [ s for s in subject_list if s not in exclude_subjects ]\n",
    "    print('\\n\\nApplied subject inclusion list:\\n\\t',' '.join(exclude_subjects))\n",
    "except:\n",
    "    print('\\n\\nNo subject exclusions applied')\n",
    "\n",
    "try:\n",
    "    subject_list = [ s for s in subject_list if s in include_subjects ]\n",
    "    print('\\n\\nApplied subject inclusion list:\\n\\t',' '.join(include_subjects))\n",
    "except:\n",
    "    print('\\n\\nNo subject inclusions applied')\n",
    "\n",
    "    \n",
    "print('\\n\\nSUBJECT LIST IS:\\n\\t', ' '.join(subject_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up nodes for file handling and subject selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `infosource` node\n",
    "\n",
    "* iterate over list of subject ids and generate subject ids and produce list of contrasts for subsequent nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = pe.Node(util.IdentityInterface(fields=['subject_id', 'resolution']),\n",
    "                  name=\"infosource\")\n",
    "\n",
    "ref_image_dict = {'low': '/data00/projects/megameta/templates/reference_low_wad.nii',\n",
    "                  'medium': '/data00/projects/megameta/templates/reference_medium_wad.nii',\n",
    "                  'high': '/data00/projects/megameta/templates/reference_high_wad.nii'}\n",
    "             \n",
    "if resolution:\n",
    "    ref_images = [v for k,v in ref_image_dict.items() if k in resolution]\n",
    "else:\n",
    "    ref_images = ref_image.dict.values()\n",
    "    \n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                       ('resolution', ref_images)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `selectfiles` node\n",
    "\n",
    "* match template to find source files (functional) for use in subsequent parts of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "\n",
    "if os.path.exists(fmriprep_dir):\n",
    "    bd='/data00/projects/megameta/{}/derivatives/fmriprep'\n",
    "    ## TODO: here need to figure out how to incorporate the run number and task name in call\n",
    "    templates = {'func': '{subject_id}/func/{subject_id}_task-'+TASK_NAME+'_run-0*_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'}       \n",
    "if os.path.exists(batch8_dir):\n",
    "    bd='/data00/projects/megameta/{}/derivatives/batch8'\n",
    "    ## TODO: here need to figure out how to incorporate the run number and task name in call\n",
    "    templates = {'func': '{subject_id}/func/{subject_id}_task-'+TASK_NAME+'_run-0*_space-MNI152-T1-1mm_desc-preproc_bold.nii.gz'}    \n",
    "\n",
    "selectfiles = pe.Node(nio.SelectFiles(templates,\n",
    "                               base_directory=bd.format(PROJECT_NAME)),\n",
    "                      working_dir=working_dir,\n",
    "                   name=\"selectfiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip and smoothing steps\n",
    "\n",
    "* BIDS derivatives folders contain unsmoothed functional NIFTI files in zipped (.nii.gz) format\n",
    "* This subflow adds three nodes:\n",
    "    1. gunzip\n",
    "    2. resample\n",
    "    3. smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify unzip node\n",
    "\n",
    "* transform `.nii.gz` to `.nii`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gunzip = pe.MapNode(Gunzip(),name=\"gunzip\", iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify smoothing node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = pe.Node(interface=spm.Smooth(), name=\"smooth\")\n",
    "fwhmlist = [4,6,8]\n",
    "\n",
    "if smoothing:\n",
    "    fwhmlist = smoothing\n",
    "\n",
    "smooth.iterables = ('fwhm', fwhmlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify resampling node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resample = pe.MapNode(interface=spm.utils.Reslice(), \n",
    "                      name='resample',\n",
    "                     iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unzip_resample_and_smooth = pe.Workflow(name='unzip_resample_and_smooth')\n",
    "\n",
    "unzip_resample_and_smooth.base_dir = os.path.join(SUBJ_DIR, working_dir)\n",
    "\n",
    "unzip_resample_and_smooth.connect(\n",
    "    [\n",
    "        (gunzip, resample, [('out_file', 'in_file')]),\n",
    "        (resample, smooth, [('out_file', 'in_files')])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify preprocessing steps datasink node\n",
    "\n",
    "* copy files to keep from various working folders to output folder for model for subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasink - creates output folder for important outputs\n",
    "pp_datasink = pe.Node(nio.DataSink(base_directory=SUBJ_DIR,\n",
    "                         parameterization=True, \n",
    "                         #container=output_dir      \n",
    "                               ),\n",
    "                name=\"pp_datasink\")\n",
    "\n",
    "pp_datasink.inputs.base_directory = output_dir\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = []\n",
    "subjFolders = [('_resolution_.*reference_(low|medium|high)_wad.nii_subject_id_%s/_fwhm_%s' % (sub,f), '\\\\1/fwhm_%s' % (f))\n",
    "               for f in fwhmlist\n",
    "               for sub in subject_list]\n",
    "substitutions.extend(subjFolders)\n",
    "pp_datasink.inputs.regexp_substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workflow for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = pe.Workflow(name='preprocessing_steps')\n",
    "preprocess.base_dir = os.path.join(SUBJ_DIR, working_dir)\n",
    "\n",
    "preprocess.connect(\n",
    "                    [ (infosource, selectfiles, [('subject_id', 'subject_id')]),\n",
    "                      (infosource, unzip_resample_and_smooth, [('resolution', \n",
    "                                                                 'resample.space_defining')]),\n",
    "                      (selectfiles, unzip_resample_and_smooth, [('func','gunzip.in_file')]),\n",
    "                      (infosource, pp_datasink, [('subject_id','container')]),\n",
    "                      (unzip_resample_and_smooth, pp_datasink, [('smooth.smoothed_files','@nii')])\n",
    "                    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
