{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second level workflow\n",
    "\n",
    "* Mar 24 2020 Jeesung \n",
    "* \n",
    "* https://miykael.github.io/nipype_tutorial/notebooks/example_2ndlevel.html\n",
    "* https://miykael.github.io/nipype_tutorial/notebooks/handson_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "\n",
    "# import functions\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "from nipype import Node, Workflow # Get the Node and Workflow object\n",
    "from nipype.interfaces.spm import (OneSampleTTestDesign, EstimateModel,\n",
    "                                   EstimateContrast, Threshold) \n",
    "\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "import nibabel as nb\n",
    "from nipype import SelectFiles\n",
    "from nipype.interfaces.io import DataSink\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "\n",
    "%matplotlib inline\n",
    "from nilearn import plotting\n",
    "from nistats import design_matrix, reporting\n",
    "\n",
    "import scipy.io as sio\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which SPM to use\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "MatlabCommand.set_default_paths(PATH_TO_SPM_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1. Experiment parameters\n",
    "\n",
    "* specify all parameters that might change between experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read json file\n",
    "\n",
    "* set output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(JSON_MODEL_FILE) as fh:\n",
    "    model_def = json.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Contrast List\n",
    "\n",
    "* find paths to all con images (=input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/data00/projects/megameta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contrast_list(model_path, cname, exclude_subjects, sample_perc=50):\n",
    "    #EDITED BY CHRISTIN to get randomly sample a given percentage of subjects for second-level model\n",
    "\n",
    "    import json\n",
    "    import random\n",
    "    import os\n",
    "    import scipy.io as sio\n",
    "    import pandas as pd\n",
    "    \n",
    "    ROOT_DIR = '/data00/projects/megameta'\n",
    "    \n",
    "    \n",
    "    def process_project(project_name, model_def, exclude_subjects=exclude_subjects,scan_all_subjs=False, DEBUG=False):\n",
    "\n",
    "        project_spec = [pspec for pspec in model_def['Projects'] if pspec['Name']==project_name]\n",
    "\n",
    "        if not project_spec:\n",
    "            print('Cannot find specification for project: ', project_name)\n",
    "            return None\n",
    "\n",
    "        model_name = project_spec[0]['Model']\n",
    "        cmap = project_spec[0]['ContrastMap']\n",
    "\n",
    "\n",
    "        model_dir = os.path.join(ROOT_DIR, project_name, \n",
    "                                 \"derivatives\", \"nipype\",\n",
    "                                 \"model_{}\".format(model_name)\n",
    "                                )\n",
    "\n",
    "        if not os.path.exists(model_dir):\n",
    "            print('Cannot find first level model directory:', model_dir)\n",
    "            return None\n",
    "\n",
    "        subjs_with_models = [s for s in os.listdir(model_dir) if s.startswith('sub-')]\n",
    "        #exclude_people\n",
    "        subjs_with_models=[s for s in subjs_with_models if s not in exclude_subjects]\n",
    "        \n",
    "        print('excluded subject list: ',exclude_subjects, ' (N=', len(exclude_subjects), ')')\n",
    "        print('included subject list: ',subjs_with_models,' (N=', len(subjs_with_models),')')\n",
    "\n",
    "        \n",
    "        #Get a random sample of participants (based on a percentage)\n",
    "#         sample_size=(sample_perc/100)*len(subjs_with_models)\n",
    "#         subj_list=random.sample(subjs_with_models,int(sample_size))\n",
    "        \n",
    "#         print('Project: {}, Sampling {} of {} participants with a model'.format(project_name, int(sample_size), len(subjs_with_models)))\n",
    "        \n",
    "#         if DEBUG:\n",
    "#             print(\"Found {} first level subject models\\n\".format(len(subjs_with_models)))\n",
    "\n",
    "\n",
    "        contrast_lists = { cname: [] for cname in cmap}\n",
    "\n",
    "\n",
    "        model_contrasts=None\n",
    "        for sidx,subj in enumerate(subjs_with_models):\n",
    "\n",
    "            if DEBUG:\n",
    "                print('Processing',subj, '-',end='')\n",
    "\n",
    "            first_level_dir = os.path.join(model_dir, subj, 'medium', 'fwhm_8')\n",
    "\n",
    "            if scan_all_subjs or sidx==0:\n",
    "                spm_mat_file = os.path.join(first_level_dir, 'SPM.mat')\n",
    "\n",
    "                SPM = sio.loadmat(spm_mat_file, squeeze_me=True, struct_as_record=False)['SPM']\n",
    "\n",
    "                model_contrasts = SPM.xCon\n",
    "\n",
    "            if DEBUG:\n",
    "                print(' found {} contrasts'.format(len(model_contrasts)))\n",
    "\n",
    "            con_map = {con.name: 'con_{:0>4}.nii'.format(cidx) for cidx,con in enumerate(model_contrasts,1) }\n",
    "\n",
    "\n",
    "            if DEBUG:\n",
    "                print('\\tContrasts are:', con_map)\n",
    "\n",
    "            for model_con, proj_con in cmap.items():\n",
    "\n",
    "                path_to_con = os.path.join(first_level_dir, con_map[proj_con])\n",
    "\n",
    "                if os.path.exists(path_to_con):\n",
    "                    contrast_lists[model_con].append(path_to_con)\n",
    "\n",
    "        return contrast_lists, subjs_with_models\n",
    "\n",
    "    with open(model_path) as fh:\n",
    "        model_def = json.load(fh)\n",
    "        \n",
    "    conlist=[]\n",
    "    subjs_with_models=[]\n",
    "    for p in model_def['Projects']:\n",
    "        cons, subjs=process_project(p['Name'], model_def)\n",
    "        conlist.extend(cons[cname])\n",
    "    \n",
    "    \n",
    "    con_df = pd.DataFrame(conlist, columns=['conpath'])\n",
    "    con_df['participant_id'] = con_df['conpath'].apply(lambda cp: cp.split('/')[8])\n",
    "    \n",
    "    \n",
    "    final_df=con_df\n",
    "    con_list = final_df['conpath'].values.tolist()\n",
    "    \n",
    "    return con_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'JSON_MODEL_FILE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-726ccba7ccec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     function=make_contrast_list), name='makecontrasts')\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ml2_getcontrasts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJSON_MODEL_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0ml2_getcontrasts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontrast_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ml2_getcontrasts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexclude_subjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_subjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'JSON_MODEL_FILE' is not defined"
     ]
    }
   ],
   "source": [
    "l2_getcontrasts = pe.Node(util.Function(input_names=['model_path','cname','exclude_subjects'],\n",
    "                                     output_names=['contrasts'],\n",
    "                                    function=make_contrast_list), name='makecontrasts')\n",
    "\n",
    "l2_getcontrasts.inputs.model_path=JSON_MODEL_FILE\n",
    "l2_getcontrasts.inputs.cname=contrast_name\n",
    "l2_getcontrasts.inputs.exclude_subjects=exclude_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load explicit mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_path='/data00/tools/spm8/apriori/brainmask_th25.nii'\n",
    "# mask = nb.load(mask_path)\n",
    "# mask.orthoview()\n",
    "# plotting.view_img(mask1) # interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Create Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd-Level Design \n",
    "\n",
    "* one-sample t-test design\n",
    "\n",
    "* This step depends on your study design and the tests you want to perform. If you're using SPM to do the group analysis, you have the liberty to choose between a factorial design, a multiple regression design, one-sample T-Test design, a paired T-Test design or a two-sample T-Test design.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the OneSampleTTestDesign node here\n",
    "onesamplettestdes = Node(OneSampleTTestDesign(), name=\"onesampttestdes\")\n",
    "\n",
    "# specify the binary mask as an explicit_mask_file for the one-sample T-test node.\n",
    "onesamplettestdes.inputs.explicit_mask_file=mask_path\n",
    "onesamplettestdes.inputs.threshold_mask_none=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the EstimateModel and the EstimateContrast node here\n",
    "\n",
    "level2estimate = Node(EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level2estimate\")\n",
    "\n",
    "level2conestimate = Node(EstimateContrast(group_contrast=True),\n",
    "                         name=\"level2conestimate\")\n",
    "\n",
    "cont01 = ['Group', 'T', ['mean'], [1]]\n",
    "level2conestimate.inputs.contrasts = [cont01]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding of output contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2thresh = Node(Threshold(contrast_index=1,\n",
    "                              use_topo_fdr=True,\n",
    "                              use_fwe_correction=False,\n",
    "                              extent_threshold=0,\n",
    "                              height_threshold=0.005,\n",
    "                              height_threshold_type='p-value',\n",
    "                              extent_fdr_p_threshold=0.05),\n",
    "                    name=\"level2thresh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify input stream (SPM12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datainput with SelectFiles and iterables\n",
    "\n",
    "* data in use: 1st level contrasts of all subjects, separated by contrast number\n",
    "* \" * \" = tell SelectFiles that it can grab available subjects and any contrast with a specific contrast id \n",
    "\n",
    "* replace this step with 'make_contrast_list' function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data output with DataSink\n",
    "\n",
    "* specify a Datasink folder to only keep those files that we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate DataSink node, create output folder for important outputs\n",
    "new_output_dir=os.path.join(output_dir)\n",
    "datasink = Node(DataSink(base_directory=new_output_dir,\n",
    "                         container=new_output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "## Use the following substitutions for the DataSink output\n",
    "substitutions = [('_contrast_id_','')] # change this \n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next step is to specify all the output that we want to keep in our output folder output. Probably best to keep are the:\n",
    "\n",
    "* the SPM.mat file and the spmT images from the EstimateContrast node\n",
    "* the thresholded spmT images from the Threshold node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Specify Workflow (SPM12)\n",
    "* Create a workflow and connect the interface nodes and the input/output stream to each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each node will be constrcuted within the workflow named 'l2analysis'\n",
    "l2analysis=Workflow(name='l2analysis', base_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect up the 2nd-level analysis components\n",
    "l2analysis.connect([\n",
    "#                     (infosource, l2_getcontrasts, [('contrast_id', 'contrast_id'),('resolution_id','resolution_id'),\n",
    "#                                                ('fwhm_id', 'fwhm_id')]),\n",
    "# #                     (selectfiles, l2_getcontrasts, [('cons', 'contrast_lists')]),\n",
    "                    (l2_getcontrasts, onesamplettestdes, [('contrasts', 'in_files')]),\n",
    "                    (onesamplettestdes, level2estimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file')]),\n",
    "                    (level2estimate, level2conestimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file'),\n",
    "                                                         ('beta_images',\n",
    "                                                          'beta_images'),\n",
    "                                                         ('residual_image',\n",
    "                                                          'residual_image')]),\n",
    "                    (level2conestimate, level2thresh, [('spm_mat_file',\n",
    "                                                        'spm_mat_file'),\n",
    "                                                       ('spmT_images',\n",
    "                                                        'stat_image'),\n",
    "                                                       ]),\n",
    "                    (level2conestimate, datasink, [('spm_mat_file',\n",
    "                                                    'contrasts.@spm_mat'),\n",
    "                                                   ('spmT_images',\n",
    "                                                    'contrasts.@T'),\n",
    "                                                   ('con_images',\n",
    "                                                    'contrasts.@con')]),\n",
    "                    (level2thresh, datasink, [('thresholded_map',\n",
    "                                               'contrasts.@threshold')]),\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
