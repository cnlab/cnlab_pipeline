{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building second level models using _nipype_ and _SPM12_\n",
    "\n",
    "## Base functionality for _megameta_ project\n",
    "\n",
    "-------\n",
    "#### History\n",
    "* 11/14/19 mbod - add contrast checks and flow\n",
    "* 11/6/19 mbod - update and test for ind behavior change for pure message\n",
    "* 5/4/19 cscholz - add datasink, incorporate mreg design, incorporate sampling of first-level contrast based on percentage of available first-level models per project\n",
    "* 4/15/19 mbod - incorporate function to read the 2nd level JSON model config\n",
    "* 4/9/19 mbod - modify template to work with fmriprep processed data\n",
    "* 3/20/19 mbod - initial setup for testing some simple one sample t-test models\n",
    "-----\n",
    "\n",
    "### Description\n",
    "\n",
    "* Set up a nipype workflow to use SPM12 to make second level models for _megameta_ task data (preprocessed using `batch8` SPM8 scripts) in BIDS derivative format   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os  # system functions\n",
    "\n",
    "# NIYPE FUNCTIONS\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.modelgen as model   # model specification\n",
    "from nipype.interfaces.base import Bunch\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matlab path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH_TO_SPM_FOLDER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1058858492e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMatlabCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_matlab_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matlab -nodesktop -nosplash\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# If SPM is not in your MATLAB path you should add it here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMatlabCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_SPM_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH_TO_SPM_FOLDER' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the way matlab should be called\n",
    "mlab.MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "# If SPM is not in your MATLAB path you should add it here\n",
    "mlab.MatlabCommand.set_default_paths(PATH_TO_SPM_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_DIR = '/data00/projects/megameta/group_models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load JSON model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_MODEL_FILE = os.path.join('/data00/projects/megameta/scripts/jupyter_megameta/second_level_models',\n",
    "                               'model_specifications',\n",
    "                               MODEL_SPEC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(JSON_MODEL_FILE) as fh:\n",
    "    model_def = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = model_def['ModelName']\n",
    "\n",
    "CONTRASTS = model_def['Contrasts']\n",
    "\n",
    "ROOT_DIR = '/data00/projects/megameta'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_contrast_list = CONTRASTS # list of specific contrast files to use in 2nd level model (include .nii?)\n",
    "\n",
    "output_dir = os.path.join(GROUP_DIR,'derivatives', 'nipype','model_2nd-level_{}'.format(MODEL_NAME))        \n",
    "working_dir = os.path.join(GROUP_DIR, 'working', \n",
    "                           'nipype', 'workingdir_model_2nd-level_{}'.format(MODEL_NAME))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "if not os.path.exists(working_dir):\n",
    "    os.makedirs(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of contrast files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "l2_infosource = pe.Node(util.IdentityInterface(fields=['contrast_id']),\n",
    "                  name=\"infosource\")\n",
    "\n",
    "smoothing_kernels = [ 8 ]\n",
    "resolutions = ['medium']\n",
    "\n",
    "resolution_and_kernel_list = product(resolutions, smoothing_kernels)\n",
    "\n",
    "\n",
    "l2_infosource.iterables = [('contrast_id', l2_contrast_list), \n",
    "                           ('resolution_and_smoothing', resolution_and_kernel_list)\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "\n",
    "subject_pattern='*'\n",
    "OUTPUT_DIR = output_dir\n",
    "l2_output_dir = output_dir\n",
    "\n",
    "l2_templates = {'cons': os.path.join(output_dir, MODEL_NAME, subject_pattern, '{smoothing_ksize}',\n",
    "                         '{contrast_id}.nii')}\n",
    "\n",
    "l2_selectfiles = pe.Node(nio.SelectFiles(l2_templates,\n",
    "                               base_directory=OUTPUT_DIR,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contrast_list(model_path, cname, sample_perc=100):\n",
    "    #EDITED BY CHRISTIN to get randomly sample a given percentage of subjects for second-level model\n",
    "\n",
    "    import json\n",
    "    import random\n",
    "    import os\n",
    "    import scipy.io as sio\n",
    "    import pandas as pd\n",
    "    \n",
    "    ROOT_DIR = '/data00/projects/megameta'\n",
    "    \n",
    "    \n",
    "    def get_mreg(model_path, DEBUG=True):\n",
    "        import json\n",
    "        import os\n",
    "        import pandas as pd\n",
    "\n",
    "        ROOT_DIR = '/data00/projects/megameta'\n",
    "\n",
    "\n",
    "        with open(model_path) as fh:\n",
    "            model_def = json.load(fh)\n",
    "\n",
    "        if not model_def:\n",
    "            return None\n",
    "\n",
    "        mreg_file='{}.tsv'.format(model_def['Regressors']['Name'])\n",
    "\n",
    "        mreg_cols = model_def['Regressors']['Columns']\n",
    "\n",
    "        project_phenotype_file = [os.path.join(ROOT_DIR,project['Name'], 'phenotype', mreg_file) for project in model_def['Projects']]\n",
    "\n",
    "        data=[]\n",
    "        for p in project_phenotype_file:\n",
    "            if not os.path.exists(p):\n",
    "                print('ERROR cannot find', p)\n",
    "            else:\n",
    "                df=pd.read_csv(p, sep='\\t')\n",
    "\n",
    "                # check to see if the participant_id column has compliant BIDS subject ids with sub- format\n",
    "                df.loc[-df['participant_id'].str.startswith('sub-'), 'participant_id'] = 'sub-'+df['participant_id']\n",
    "\n",
    "\n",
    "                # drop rows with NAs in regressor columns\n",
    "                df = df[df[mreg_cols].notnull().all(axis=1)]\n",
    "\n",
    "                data.append(df)\n",
    "\n",
    "        return pd.concat(data), mreg_cols\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def process_project(project_name, model_def, scan_all_subjs=False, DEBUG=False):\n",
    "\n",
    "        project_spec = [pspec for pspec in model_def['Projects'] if pspec['Name']==project_name]\n",
    "\n",
    "        if not project_spec:\n",
    "            print('Cannot find specification for project: ', project_name)\n",
    "            return None\n",
    "\n",
    "        model_name = project_spec[0]['Model']\n",
    "        cmap = project_spec[0]['ContrastMap']\n",
    "\n",
    "\n",
    "        model_dir = os.path.join(ROOT_DIR, project_name, \n",
    "                                 \"derivatives\", \"nipype\",\n",
    "                                 \"model_{}\".format(model_name)\n",
    "                                )\n",
    "\n",
    "        if not os.path.exists(model_dir):\n",
    "            print('Cannot find first level model directory:', model_dir)\n",
    "            return None\n",
    "\n",
    "        subjs_with_models = [s for s in os.listdir(model_dir) if s.startswith('sub-')]\n",
    "        \n",
    "        \n",
    "        #Get a random sample of participants (based on a percentage)\n",
    "        sample_size=(sample_perc/100)*len(subjs_with_models)\n",
    "        subj_list=random.sample(subjs_with_models,int(sample_size))\n",
    "        \n",
    "        print('Project: {}, Sampling {} of {} participants with a model'.format(project_name, int(sample_size), len(subjs_with_models)))\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"Found {} first level subject models\\n\".format(len(subjs_with_models)))\n",
    "\n",
    "\n",
    "        contrast_lists = { cname: [] for cname in cmap}\n",
    "\n",
    "\n",
    "        model_contrasts=None\n",
    "        for sidx,subj in enumerate(subj_list):\n",
    "\n",
    "            if DEBUG:\n",
    "                print('Processing',subj, '-',end='')\n",
    "\n",
    "            first_level_dir = os.path.join(model_dir, subj, 'medium', 'fwhm_8')\n",
    "\n",
    "            if scan_all_subjs or sidx==0:\n",
    "                spm_mat_file = os.path.join(first_level_dir, 'SPM.mat')\n",
    "\n",
    "                SPM = sio.loadmat(spm_mat_file, squeeze_me=True, struct_as_record=False)['SPM']\n",
    "\n",
    "                model_contrasts = SPM.xCon\n",
    "\n",
    "            if DEBUG:\n",
    "                print(' found {} contrasts'.format(len(model_contrasts)))\n",
    "\n",
    "            con_map = {con.name: 'con_{:0>4}.nii'.format(cidx) for cidx,con in enumerate(model_contrasts,1) }\n",
    "\n",
    "\n",
    "            if DEBUG:\n",
    "                print('\\tContrasts are:', con_map)\n",
    "\n",
    "            for model_con, proj_con in cmap.items():\n",
    "\n",
    "                path_to_con = os.path.join(first_level_dir, con_map[proj_con])\n",
    "\n",
    "                if os.path.exists(path_to_con):\n",
    "                    contrast_lists[model_con].append(path_to_con)\n",
    "\n",
    "        return contrast_lists, subjs_with_models\n",
    "\n",
    "\n",
    "    with open(model_path) as fh:\n",
    "        model_def = json.load(fh)\n",
    "        if model_def.get('Regressors',False):\n",
    "            mreg_df, mreg_cols=get_mreg(model_path)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    conlist=[]\n",
    "    subjs_with_models=[]\n",
    "    for p in model_def['Projects']:\n",
    "        cons, subjs=process_project(p['Name'], model_def)\n",
    "        conlist.extend(cons[cname])\n",
    "    \n",
    "    \n",
    "    con_df = pd.DataFrame(conlist, columns=['conpath'])\n",
    "    con_df['participant_id'] = con_df['conpath'].apply(lambda cp: cp.split('/')[8])\n",
    "    \n",
    "    \n",
    "    final_df = con_df.merge(mreg_df)\n",
    "        \n",
    "    mregs=[]\n",
    "    for k,v in final_df[mreg_cols].to_dict(orient='list').items():\n",
    "        mregs.append({'name': k, 'vector': v, 'centering': 5})   # value of 5 for centering is iCC = 5 (no centuring in the spm_factorial model)\n",
    "\n",
    "\n",
    "    # Ad covariates to conrol for behavior change\n",
    "    # mregdesign.inputs.covariates=mregs\n",
    "    \n",
    "    con_list = final_df['conpath'].values.tolist()\n",
    "    \n",
    "    return con_list, mregs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_getcontrasts = pe.Node(util.Function(input_names=['model_path','cname'],\n",
    "                                     output_names=['contrasts', 'covariates'],\n",
    "                                      function=make_contrast_list),\n",
    "                    name='makecontrasts')\n",
    "MDIR = os.path.abspath('../model_specifications')\n",
    "l2_getcontrasts.inputs.model_path=os.path.join(MDIR, MODEL_SPEC_FILE)\n",
    "l2_getcontrasts.inputs.cname=CONTRAST_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDITED BY CHRISTIN (ADDING DATASINK)\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = pe.Node(nio.DataSink(base_directory=OUTPUT_DIR,\n",
    "                         container=l2_output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = [('_contrast_id_', '')]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "osttdesign = pe.Node(spm.model.OneSampleTTestDesign(),\n",
    "                         name=\"osttdesign\")\n",
    "\n",
    "osttdesign.inputs.explicit_mask_file='/data00/tools/spm8/apriori/brainmask_th25.nii'\n",
    "osttdesign.inputs.threshold_mask_none=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDITED BY CHRISTIN TO IMPPLEMENT MREG\n",
    "\n",
    "# Multiple Regression Design - creates mreg Design\n",
    "mregdesign = pe.Node(spm.model.MultipleRegressionDesign(),\n",
    "                         name=\"mregdesign\")\n",
    "mregdesign.inputs.threshold_mask_none=True\n",
    "#mregdesign.inputs.explicit_mask_file='/data00/tools/spm8/apriori/brainmask_th25.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstimateModel - estimate the parameters of the model\n",
    "level2estimate = pe.Node(spm.model.EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level2estimate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstimateContrast - estimates simple group contrast\n",
    "level2conestimate = pe.Node(spm.model.EstimateContrast(group_contrast=True),\n",
    "                         name=\"level2conestimate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'level2conestimate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e154e1d43d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlevel2conestimate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcont1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcont2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'level2conestimate' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "cont1 = ['QuitIntent', 'T', ['QuitIntent', 'FTND', 'mean_WC', 'mean'], [1, 0, 0, 0]]\n",
    "cont2 = ['FTND', 'T', ['QuitIntent', 'FTND', 'mean_WC', 'mean'], [0, 1, 0, 0]]\n",
    "cont3 = ['mean_WC', 'T', ['QuitIntent', 'FTND', 'mean_WC', 'mean'], [0, 0, 1, 0]]\n",
    "cont4 = ['mean', 'T', ['QuitIntent', 'FTND', 'mean_WC', 'mean'], [0, 0, 0, 1]]\n",
    "'''\n",
    "# cont1 = ['Change', 'T', ['change', 'baseline','mean'], [1,0,0]] \n",
    "# cont2 = ['Baseline', 'T', ['change', 'baseline', 'mean'], [0,1,0]]\n",
    "# cont3 = ['Group', 'T', ['change','baseline', 'mean'], [0,0,1]] \n",
    "\n",
    "# level2conestimate.inputs.contrasts = [cont1,cont2, cont3]\n",
    "\n",
    "cont1 = ['Change', 'T', ['change', 'mean'], [1,0]] \n",
    "cont2 = ['Group', 'T', ['change','mean'], [0,1]] \n",
    "\n",
    "level2conestimate.inputs.contrasts = [cont1,cont2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup second level workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l2_working_dir = os.path.join(PROJECT_DIR, 'nipype', 'workingdir_banner_2nd_level')\n",
    "l2_working_dir = working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDITED BY CHRISTIN (adding datasink to the workflow)\n",
    "l2analysis = pe.Workflow(name='l2analysis')\n",
    "\n",
    "l2analysis.base_dir = l2_working_dir\n",
    "\n",
    "# Connect up the 2nd-level analysis components\n",
    "l2analysis.connect(\n",
    "                    [\n",
    "                        \n",
    "                    #(l2_infosource, l2_getcontrasts, [('contrast_id', 'contrast_id'),\n",
    "                     #                                ('model_path')]),\n",
    "                     \n",
    "                     (l2_getcontrasts,  mregdesign, [('contrasts', 'in_files'),\n",
    "                                                     ('covariates', 'covariates')]),\n",
    "                     \n",
    "                    (mregdesign, level2estimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file')] ),\n",
    "                    (level2estimate, level2conestimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file'),\n",
    "                                                         ('beta_images',\n",
    "                                                          'beta_images'),\n",
    "                                                         ('residual_image',\n",
    "                                                          'residual_image')]),\n",
    "                    (level2conestimate, datasink, [('spm_mat_file',\n",
    "                                                    'contrasts.@spm_mat'),\n",
    "                                                   ('spmT_images',\n",
    "                                                    'contrasts.@T'),\n",
    "                                                   ('con_images',\n",
    "                                                    'contrasts.@con')])\n",
    "                    ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
