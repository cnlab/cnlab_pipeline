{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building first level models using _nipype_ and _SPM12_\n",
    "\n",
    "## Base functionality for _megameta_ project - preprocessing steps\n",
    "\n",
    "-------\n",
    "#### History\n",
    "\n",
    "* 4/7/19 mbod - modify template and functions for fmrirprep processed data\n",
    "* 3/29/19 mbod - split preprocessing (unzip, resample, smooth) from modeling steps\n",
    "* 3/28/19 mbod - update pipeline to include resampling to template & SPM path reference\n",
    "* 3/23/19 mbod - include contrast definition in the config JSON file\n",
    "* 3/9/19 mbod - updates from testing template with `darpa1`\n",
    "* 2/27/19 mbod  - modify example notebook to make base functionality notebook\n",
    "\n",
    "-----\n",
    "\n",
    "### Description\n",
    "\n",
    "* Set up a nipype workflow to use SPM12 to make first level models for _megameta_ task data (preprocessed using `batch8` SPM8 scripts) in BIDS derivative format   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "### Template variables\n",
    "\n",
    "* Specify the following values:\n",
    "    1. project name - should be name of folder under `/data00/project/megameta`, e.g. `project1`\n",
    "    2. filename for JSON model specification (should be inside `model_specification` folder), e.g. `p1_image_pmod_likeme.json`\n",
    "    3. TR value in seconds\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "### Setup\n",
    "\n",
    "* import required modules and define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os  # system functions\n",
    "\n",
    "# NIYPE FUNCTIONS\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.modelgen as model   # model specification\n",
    "from nipype.interfaces.base import Bunch\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from nilearn import plotting, image\n",
    "from nistats import thresholding\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matlab path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the way matlab should be called\n",
    "mlab.MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "# If SPM is not in your MATLAB path you should add it here\n",
    "mlab.MatlabCommand.set_default_paths(PATH_TO_SPM_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "* These need to be reformatted to be consistent\n",
    "* as data is not smoothed commented out the `fwhm_size` param - but data probably has a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join('/data00/projects/megameta', PROJECT_NAME)\n",
    "SUBJ_DIR = os.path.join(PROJECT_DIR, 'derivatives', 'fmriprep')\n",
    "\n",
    "\n",
    "task_func_template = \"{PID}_task-{TASK}_run-0{RUN}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\"\n",
    "task_func_template2 = \"{PID}_task-{TASK}_run-0{RUN}_bold_space-MNI152NLin2009cAsym_preproc.nii.gz\"\n",
    "\n",
    "subject_list = [subj for subj in os.listdir(SUBJ_DIR) \n",
    "                   if os.path.exists(os.path.join(SUBJ_DIR,subj,'func',\n",
    "                                        task_func_template.format(PID=subj, TASK=TASK_NAME, RUN=1)))\n",
    "                   or os.path.exists(os.path.join(SUBJ_DIR,subj,'func',\n",
    "                                        task_func_template2.format(PID=subj, TASK=TASK_NAME, RUN=1)))\n",
    "               ]\n",
    "\n",
    "output_dir = os.path.join(PROJECT_DIR,'derivatives', 'nipype','resampled_and_smoothed')        # name of output folder\n",
    "working_dir = os.path.join(PROJECT_DIR, 'working', \n",
    "                           'nipype', 'workingdir_preproc_{}'.format(TASK_NAME.upper()))   # name of working directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check to see if output and work directories exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir) \n",
    "\n",
    "if not os.path.exists(working_dir):\n",
    "    os.makedirs(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No subject exclusions applied\n",
      "\n",
      "\n",
      "No subject inclusions applied\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'subject_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-495531dbb9e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\nSUBJECT LIST IS:\\n\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subject_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    subject_list = [ s for s in subject_list if s not in exclude_subjects ]\n",
    "    print('\\n\\nApplied subject inclusion list:\\n\\t',' '.join(exclude_subjects))\n",
    "except:\n",
    "    print('\\n\\nNo subject exclusions applied')\n",
    "\n",
    "try:\n",
    "    subject_list = [ s for s in subject_list if s in include_subjects ]\n",
    "    print('\\n\\nApplied subject inclusion list:\\n\\t',' '.join(include_subjects))\n",
    "except:\n",
    "    print('\\n\\nNo subject inclusions applied')\n",
    "\n",
    "    \n",
    "print('\\n\\nSUBJECT LIST IS:\\n\\t', ' '.join(subject_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up nodes for file handling and subject selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `infosource` node\n",
    "\n",
    "* iterate over list of subject ids and generate subject ids and produce list of contrasts for subsequent nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = pe.Node(util.IdentityInterface(fields=['subject_id', 'resolution']),\n",
    "                  name=\"infosource\")\n",
    "\n",
    "ref_image_dict = {'low': '/data00/projects/megameta/templates/reference_low_wad.nii',\n",
    "                  'medium': '/data00/projects/megameta/templates/reference_medium_wad.nii',\n",
    "                  'high': '/data00/projects/megameta/templates/reference_high_wad.nii'}\n",
    "             \n",
    "if resolution:\n",
    "    ref_images = [v for k,v in ref_image_dict.items() if k in resolution]\n",
    "else:\n",
    "    ref_images = ref_image.dict.values()\n",
    "    \n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                       ('resolution', ref_images)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `selectfiles` node\n",
    "\n",
    "* match template to find source files (functional) for use in subsequent parts of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "\n",
    "\n",
    "## TODO: here need to figure out how to incorporate the run number and task name in call\n",
    "templates = {'func': '{subject_id}/func/{subject_id}_task-'+TASK_NAME+'_run-0*_*pace-MNI152NLin2009cAsym_*prepro*.nii.gz'}          \n",
    "\n",
    "\n",
    "\n",
    "selectfiles = pe.Node(nio.SelectFiles(templates,\n",
    "                               base_directory='/data00/projects/megameta/{}/derivatives/fmriprep'.format(PROJECT_NAME)),\n",
    "                      working_dir=working_dir,\n",
    "                   name=\"selectfiles\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip and smoothing steps\n",
    "\n",
    "* BIDS derivatives folders contain unsmoothed functional NIFTI files in zipped (.nii.gz) format\n",
    "* This subflow adds three nodes:\n",
    "    1. gunzip\n",
    "    2. resample\n",
    "    3. smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify unzip node\n",
    "\n",
    "* transform `.nii.gz` to `.nii`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gunzip = pe.MapNode(Gunzip(),name=\"gunzip\", iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify smoothing node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = pe.Node(interface=spm.Smooth(), name=\"smooth\")\n",
    "fwhmlist = [4,6,8]\n",
    "\n",
    "if smoothing:\n",
    "    fwhmlist = smoothing\n",
    "\n",
    "smooth.iterables = ('fwhm', fwhmlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify resampling node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resample = pe.MapNode(interface=spm.utils.Reslice(), \n",
    "                      name='resample',\n",
    "                     iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unzip_resample_and_smooth = pe.Workflow(name='unzip_resample_and_smooth')\n",
    "\n",
    "unzip_resample_and_smooth.base_dir = os.path.join(SUBJ_DIR, working_dir)\n",
    "\n",
    "unzip_resample_and_smooth.connect(\n",
    "    [\n",
    "        (gunzip, resample, [('out_file', 'in_file')]),\n",
    "        (resample, smooth, [('out_file', 'in_files')])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify preprocessing steps datasink node\n",
    "\n",
    "* copy files to keep from various working folders to output folder for model for subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasink - creates output folder for important outputs\n",
    "pp_datasink = pe.Node(nio.DataSink(base_directory=SUBJ_DIR,\n",
    "                         parameterization=True, \n",
    "                         #container=output_dir      \n",
    "                               ),\n",
    "                name=\"pp_datasink\")\n",
    "\n",
    "pp_datasink.inputs.base_directory = output_dir\n",
    "\n",
    "# Use the following DataSink output substitutions\n",
    "substitutions = []\n",
    "subjFolders = [('_resolution_.*reference_(low|medium|high)_wad.nii_subject_id_%s/_fwhm_%s' % (sub,f), '\\\\1/fwhm_%s' % (f))\n",
    "               for f in fwhmlist\n",
    "               for sub in subject_list]\n",
    "substitutions.extend(subjFolders)\n",
    "pp_datasink.inputs.regexp_substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workflow for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = pe.Workflow(name='preprocessing_steps')\n",
    "preprocess.base_dir = os.path.join(SUBJ_DIR, working_dir)\n",
    "\n",
    "preprocess.connect(\n",
    "                    [ (infosource, selectfiles, [('subject_id', 'subject_id')]),\n",
    "                      (infosource, unzip_resample_and_smooth, [('resolution', \n",
    "                                                                 'resample.space_defining')]),\n",
    "                      (selectfiles, unzip_resample_and_smooth, [('func','gunzip.in_file')]),\n",
    "                      (infosource, pp_datasink, [('subject_id','container')]),\n",
    "                      (unzip_resample_and_smooth, pp_datasink, [('smooth.smoothed_files','@nii')])\n",
    "                    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
