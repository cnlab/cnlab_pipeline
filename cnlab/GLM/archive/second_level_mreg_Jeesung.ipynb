{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second level workflow\n",
    "\n",
    "* Mar 24 2020 Jeesung \n",
    "* based on CNLab pipeline\n",
    "* https://miykael.github.io/nipype_tutorial/notebooks/example_2ndlevel.html\n",
    "* https://miykael.github.io/nipype_tutorial/notebooks/handson_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200427-07:50:10,748 nipype.utils INFO:\n",
      "\t No new version available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: \n",
      "\n",
      " | Starting with Nilearn 0.7.0, all Nistats functionality has been incorporated into Nilearn's stats & reporting modules.\n",
      " | Nistats package will no longer be updated or maintained.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "\n",
    "# import functions\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "from nipype import Node, Workflow # Get the Node and Workflow object\n",
    "from nipype.interfaces.spm import (OneSampleTTestDesign, MultipleRegressionDesign, EstimateModel,\n",
    "                                   EstimateContrast, Threshold) \n",
    "\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "import nibabel as nb\n",
    "from nipype import SelectFiles\n",
    "from nipype.interfaces.io import DataSink\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "\n",
    "%matplotlib inline\n",
    "from nilearn import plotting\n",
    "from nistats import design_matrix, reporting\n",
    "\n",
    "import scipy.io as sio\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH_TO_SPM_FOLDER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-802e7aa857d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Specify which SPM to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMatlabCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_matlab_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matlab -nodesktop -nosplash\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMatlabCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_SPM_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH_TO_SPM_FOLDER' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify which SPM to use\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "MatlabCommand.set_default_paths(PATH_TO_SPM_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1. Experiment parameters\n",
    "\n",
    "* specify all parameters that might change between experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read json file\n",
    "\n",
    "* set output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON_MODEL_FILE = os.path.join('/data00/projects/megameta/scripts/jupyter_megameta/second_level_models',\n",
    "#                                'model_specifications','Framing',\n",
    "#                                MODEL_SPEC_FILE)\n",
    "\n",
    "# with open(JSON_MODEL_FILE) as fh:\n",
    "#     model_def = json.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Contrast List\n",
    "\n",
    "* find paths to all con images (=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/data00/projects/megameta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contrast_list(model_path, cname, exclude_subjects, sample_perc=100):\n",
    "    #EDITED BY CHRISTIN to get randomly sample a given percentage of subjects for second-level model\n",
    "\n",
    "    import json\n",
    "    import random\n",
    "    import os\n",
    "    import scipy.io as sio\n",
    "    import pandas as pd\n",
    "    \n",
    "    ROOT_DIR = '/data00/projects/megameta'\n",
    "    \n",
    "    \n",
    "    def get_mreg(model_path, DEBUG=True):\n",
    "        import json\n",
    "        import os\n",
    "        import pandas as pd\n",
    "\n",
    "        ROOT_DIR = '/data00/projects/megameta'\n",
    "\n",
    "\n",
    "        with open(model_path) as fh:\n",
    "            model_def = json.load(fh)\n",
    "\n",
    "        if not model_def:\n",
    "            return None\n",
    "\n",
    "        mreg_file='{}.csv'.format(model_def['Regressors']['Name'])\n",
    "\n",
    "        mreg_cols = model_def['Regressors']['Columns']\n",
    "\n",
    "        project_phenotype_file = [os.path.join(ROOT_DIR,project['Name'], 'phenotype', mreg_file) for project in model_def['Projects']]\n",
    "\n",
    "        data=[]\n",
    "        for p in project_phenotype_file:\n",
    "            if not os.path.exists(p):\n",
    "                print('ERROR cannot find', p)\n",
    "            else:\n",
    "#                 df=pd.read_csv(p, sep='\\t')\n",
    "                df=pd.read_csv(p)\n",
    "                # check to see if the participant_id column has compliant BIDS subject ids with sub- format\n",
    "                df.loc[-df['participant_id'].str.startswith('sub-'), 'participant_id'] = 'sub-'+df['participant_id']\n",
    "\n",
    "\n",
    "                # drop rows with NAs in regressor columns\n",
    "                df = df[df[mreg_cols].notnull().all(axis=1)]\n",
    "\n",
    "                data.append(df)\n",
    "\n",
    "        return pd.concat(data), mreg_cols\n",
    "    \n",
    "    \n",
    "    def process_project(project_name, model_def,exclude_subjects=exclude_subjects, scan_all_subjs=False, DEBUG=False):\n",
    "\n",
    "        project_spec = [pspec for pspec in model_def['Projects'] if pspec['Name']==project_name]\n",
    "\n",
    "        if not project_spec:\n",
    "            print('Cannot find specification for project: ', project_name)\n",
    "            return None\n",
    "\n",
    "        model_name = project_spec[0]['Model']\n",
    "        cmap = project_spec[0]['ContrastMap']\n",
    "\n",
    "\n",
    "        model_dir = os.path.join(ROOT_DIR, project_name, \n",
    "                                 \"derivatives\", \"nipype\",\n",
    "                                 \"model_{}\".format(model_name)\n",
    "                                )\n",
    "\n",
    "        if not os.path.exists(model_dir):\n",
    "            print('Cannot find first level model directory:', model_dir)\n",
    "            return None\n",
    "\n",
    "        subjs_with_models = [s for s in os.listdir(model_dir) if s.startswith('sub-')]\n",
    "        #exclude_people\n",
    "        subjs_with_models=[s for s in subjs_with_models if s not in exclude_subjects]\n",
    "        \n",
    "        print('excluded subject list: ',exclude_subjects, ' (N=', len(exclude_subjects), ')')\n",
    "        print('included subject list: ',subjs_with_models,' (N=', len(subjs_with_models),')')\n",
    "\n",
    "        \n",
    "        #Get a random sample of participants (based on a percentage)\n",
    "        sample_size=(sample_perc/100)*len(subjs_with_models)\n",
    "        subj_list=random.sample(subjs_with_models,int(sample_size))\n",
    "        \n",
    "        print('Project: {}, Sampling {} of {} participants with a model'.format(project_name, int(sample_size), len(subj_list)))\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"Found {} first level subject models\\n\".format(len(subjs_with_models)))\n",
    "\n",
    "\n",
    "        contrast_lists = { cname: [] for cname in cmap}\n",
    "\n",
    "\n",
    "        model_contrasts=None\n",
    "        for sidx,subj in enumerate(subj_list):\n",
    "\n",
    "            if DEBUG:\n",
    "                print('Processing',subj, '-',end='')\n",
    "\n",
    "            first_level_dir = os.path.join(model_dir, subj, 'medium', 'fwhm_8')\n",
    "\n",
    "            if scan_all_subjs or sidx==0:\n",
    "                spm_mat_file = os.path.join(first_level_dir, 'SPM.mat')\n",
    "\n",
    "                SPM = sio.loadmat(spm_mat_file, squeeze_me=True, struct_as_record=False)['SPM']\n",
    "\n",
    "                model_contrasts = SPM.xCon\n",
    "\n",
    "            if DEBUG:\n",
    "                print(' found {} contrasts'.format(len(model_contrasts)))\n",
    "\n",
    "            con_map = {con.name: 'con_{:0>4}.nii'.format(cidx) for cidx,con in enumerate(model_contrasts,1) }\n",
    "\n",
    "\n",
    "            if DEBUG:\n",
    "                print('\\tContrasts are:', con_map)\n",
    "\n",
    "            for model_con, proj_con in cmap.items():\n",
    "\n",
    "                path_to_con = os.path.join(first_level_dir, con_map[proj_con])\n",
    "\n",
    "                if os.path.exists(path_to_con):\n",
    "                    contrast_lists[model_con].append(path_to_con)\n",
    "\n",
    "        return contrast_lists, subjs_with_models\n",
    "\n",
    "    with open(model_path) as fh:\n",
    "        model_def = json.load(fh)\n",
    "        if model_def.get('Regressors',False):\n",
    "            mreg_df, mreg_cols=get_mreg(model_path)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    conlist=[]\n",
    "    subjs_with_models=[]\n",
    "    for p in model_def['Projects']:\n",
    "        cons, subjs=process_project(p['Name'], model_def, exclude_subjects)\n",
    "        conlist.extend(cons[cname])\n",
    "    \n",
    "    \n",
    "    con_df = pd.DataFrame(conlist, columns=['conpath'])\n",
    "    con_df['participant_id'] = con_df['conpath'].apply(lambda cp: cp.split('/')[8])\n",
    "    \n",
    "    final_df=pd.merge(con_df,mreg_df,on='participant_id')\n",
    "\n",
    "        \n",
    "    mregs=[]\n",
    "    for k,v in final_df[mreg_cols].to_dict(orient='list').items():\n",
    "        mregs.append({'name': k, 'vector': v, 'centering': 5})   # value of 5 for centering is iCC = 5 (no centuring in the spm_factorial model)\n",
    "\n",
    "    \n",
    "    con_list = final_df['conpath'].values.tolist()\n",
    "\n",
    "\n",
    "    print('Participants with both first level models and behavior data N=',len(mregs[0]['vector']))\n",
    "    return con_list, mregs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_getcontrasts = pe.Node(util.Function(input_names=['model_path','cname','exclude_subjects'],\n",
    "                                     output_names=['contrasts','covariates'],\n",
    "                                    function=make_contrast_list), name='makecontrasts')\n",
    "\n",
    "l2_getcontrasts.inputs.model_path=JSON_MODEL_FILE\n",
    "l2_getcontrasts.inputs.cname=contrast_name\n",
    "l2_getcontrasts.inputs.exclude_subjects=exclude_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load explicit mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_path='/data00/tools/spm8/apriori/brainmask_th25.nii'\n",
    "# mask = nb.load(mask_path)\n",
    "# # mask.orthoview()\n",
    "# # plotting.view_img(mask1) # interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Create Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd-Level Design \n",
    "\n",
    "* one-sample t-test design\n",
    "\n",
    "* This step depends on your study design and the tests you want to perform. If you're using SPM to do the group analysis, you have the liberty to choose between a factorial design, a multiple regression design, one-sample T-Test design, a paired T-Test design or a two-sample T-Test design.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Infosource - a function free node to iterate over the list of subject names\n",
    "# l2_infosource = pe.Node(util.IdentityInterface(fields=['contrast_id']),\n",
    "#                   name=\"infosource\")\n",
    "\n",
    "# smoothing_kernels = [ 8 ]\n",
    "# resolutions = ['medium']\n",
    "\n",
    "# resolution_and_kernel_list = product(resolutions, smoothing_kernels)\n",
    "\n",
    "\n",
    "# l2_infosource.iterables = [('contrast_id', contrast_name), \n",
    "#                            ('resolution_and_smoothing', resolution_and_kernel_list)\n",
    "#                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the OneSampleTTestDesign node here\n",
    "onesamplettestdes = Node(OneSampleTTestDesign(), name=\"onesampttestdes\")\n",
    "\n",
    "# specify the binary mask as an explicit_mask_file for the one-sample T-test node.\n",
    "onesamplettestdes.inputs.explicit_mask_file=mask_path\n",
    "onesamplettestdes.inputs.threshold_mask_none=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mregs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a7a72159cd26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Add covariates to control for behavior change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmregdesign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmregs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mregs' is not defined"
     ]
    }
   ],
   "source": [
    "# Multiple Regression Design - creates mreg Design\n",
    "mregdesign = Node(MultipleRegressionDesign(),name=\"mregdesign\")\n",
    "mregdesign.inputs.threshold_mask_none=True\n",
    "\n",
    "# mregs=make_contrast_list(JSON_MODEL_FILE, contrast_name,exclude_subjects)[1]\n",
    "# # # Add covariates to control for behavior change\n",
    "# mregdesign.inputs.covariates=l2_getcontrasts.outputs.covariates\n",
    "\n",
    "# print('Participants with both first level models and behavior data N=',len(mregs[0]['vector']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the EstimateModel and the EstimateContrast node here\n",
    "\n",
    "level2estimate = Node(EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      name=\"level2estimate\")\n",
    "\n",
    "level2conestimate = Node(EstimateContrast(group_contrast=True),\n",
    "                         name=\"level2conestimate\")\n",
    "\n",
    "\n",
    "# cont1 = ['Change', 'T', ['change','baseline','mean'], [1,0,0]]\n",
    "# cont2 = ['Baseline', 'T', ['change','baseline','mean'], [0,1,0]]\n",
    "# cont3 = ['Group', 'T', ['change','baseline','mean'], [0,0,1]]\n",
    "\n",
    "# cont1 = ['Change', 'T', ['change','baseline','mean'], [1,0,0]]\n",
    "# cont2 = ['Baseline', 'T', ['change','baseline','mean'], [0,1,0]]\n",
    "# cont3 = ['Group', 'T', ['change','baseline','mean'], [0,0,1]]\n",
    "\n",
    "level2conestimate.inputs.contrasts = contrast_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding of output contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level2thresh = Node(Threshold(contrast_index=1,\n",
    "#                               use_topo_fdr=True,\n",
    "#                               use_fwe_correction=False,\n",
    "#                               extent_threshold=0,\n",
    "#                               height_threshold_type='p-value',\n",
    "#                               extent_fdr_p_threshold=0.05),\n",
    "#                     name=\"level2thresh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify input stream (SPM12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datainput with SelectFiles and iterables\n",
    "\n",
    "* data in use: 1st level contrasts of all subjects, separated by contrast number\n",
    "* \" * \" = tell SelectFiles that it can grab available subjects and any contrast with a specific contrast id \n",
    "\n",
    "* replace this step with 'make_contrast_list' function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data output with DataSink\n",
    "\n",
    "* specify a Datasink folder to only keep those files that we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate DataSink node, create output folder for important outputs\n",
    "# new_output_dir=os.path.join(output_dir,contrast_name)\n",
    "datasink = Node(DataSink(base_directory=output_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "## Use the following substitutions for the DataSink output\n",
    "substitutions = [('_contrast_id_','')] # change this \n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next step is to specify all the output that we want to keep in our output folder output. Probably best to keep are the:\n",
    "\n",
    "* the SPM.mat file and the spmT images from the EstimateContrast node\n",
    "* the thresholded spmT images from the Threshold node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Specify Workflow (SPM12)\n",
    "* Create a workflow and connect the interface nodes and the input/output stream to each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'working_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-10d3957ad1c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# each node will be constrcuted within the workflow named 'l2analysis'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml2analysis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWorkflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2analysis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworking_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'working_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# each node will be constrcuted within the workflow named 'l2analysis'\n",
    "l2analysis=Workflow(name='l2analysis', base_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l2analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eeeec8012b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Connect up the 2nd-level analysis components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m l2analysis.connect([(l2_getcontrasts,  mregdesign, [('contrasts', 'in_files'),\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                      ('covariates','covariates')]),\n\u001b[1;32m      4\u001b[0m                     (mregdesign, level2estimate, [('spm_mat_file',\n\u001b[1;32m      5\u001b[0m                                                           'spm_mat_file')]),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l2analysis' is not defined"
     ]
    }
   ],
   "source": [
    "# Connect up the 2nd-level analysis components\n",
    "l2analysis.connect([(l2_getcontrasts,  mregdesign, [('contrasts', 'in_files'),\n",
    "                                                     ('covariates','covariates')]),\n",
    "                    (mregdesign, level2estimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file')]),\n",
    "                    (level2estimate, level2conestimate, [('spm_mat_file',\n",
    "                                                          'spm_mat_file'),\n",
    "                                                         ('beta_images',\n",
    "                                                          'beta_images'),\n",
    "                                                         ('residual_image',\n",
    "                                                          'residual_image')]),\n",
    "                    (level2conestimate, datasink, [('spm_mat_file',\n",
    "                                                    'contrasts.@spm_mat'),\n",
    "                                                   ('spmT_images',\n",
    "                                                    'contrasts.@T'),\n",
    "                                                   ('con_images',\n",
    "                                                    'contrasts.@con')])\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect up the 2nd-level analysis components\n",
    "# l2analysis.connect([(l2_getcontrasts,  mregdesign, [('contrasts', 'in_files')]),\n",
    "# #                                                      ('covariates', 'covariates')]),\n",
    "#                     (mregdesign, level2estimate, [('spm_mat_file',\n",
    "#                                                           'spm_mat_file')] ),\n",
    "#                     (level2estimate, level2conestimate, [('spm_mat_file',\n",
    "#                                                           'spm_mat_file'),\n",
    "#                                                          ('beta_images',\n",
    "#                                                           'beta_images'),\n",
    "#                                                          ('residual_image',\n",
    "#                                                           'residual_image')]),\n",
    "#                     (level2conestimate, level2thresh, [('spm_mat_file',\n",
    "#                                                         'spm_mat_file'),\n",
    "#                                                        ('spmT_images',\n",
    "#                                                         'stat_image')]),\n",
    "#                     (level2conestimate, datasink, [('spm_mat_file',\n",
    "#                                                     'contrasts.@spm_mat'),\n",
    "#                                                    ('spmT_images',\n",
    "#                                                     'contrasts.@T'),\n",
    "#                                                    ('con_images',\n",
    "#                                                     'contrasts.@con')]),\n",
    "#                     (level2thresh, datasink, [('thresholded_map',\n",
    "#                                                'contrasts.@threshold')])\n",
    "#                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l2analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-f65f62a12b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml2analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel2conestimate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'l2analysis' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
